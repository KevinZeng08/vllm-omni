ARG VLLM_BASE_IMAGE=vllm/vllm-openai
ARG VLLM_BASE_TAG=v0.15.0
FROM ${VLLM_BASE_IMAGE}:${VLLM_BASE_TAG}
ARG APP_DIR=/workspace/vllm-omni
WORKDIR ${APP_DIR}

COPY . .

# Install system dependencies
RUN apt-get update && \
    apt-get install -y ffmpeg sox libsox-fmt-all && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/*

# Install vLLM wheel for the specific commit
# URL format: https://wheels.vllm.ai/<commit_hash>/
# Current vLLM commit: f97ca671766c5201404e9fc812e35bf2c4e95a01
# Note: --prerelease=allow is required because nightly/commit wheels use
# pre-release version numbers (e.g. 2.10.0.dev...) which uv ignores by default,
# causing it to fall back to the older stable release from PyPI.
RUN uv pip install --system --upgrade --force-reinstall --prerelease=allow vllm --extra-index-url https://wheels.vllm.ai/4a1550d22d7058e129d0e1257e726b3bf4a77025

# # Keep flashinfer runtime packages in version sync.
# # We derive the version from installed flashinfer (pulled by vllm)
# # and enforce the same version for flashinfer-cubin / flashinfer-jit-cache.
# RUN FLASHINFER_VERSION="$(python3 -c 'import importlib.metadata as m; print(m.version("flashinfer-python"))' 2>/dev/null || python3 -c 'import importlib.metadata as m; print(m.version("flashinfer"))')" && \
#     FLASHINFER_CUDA_TAG="$(python3 -c 'import torch; print((torch.version.cuda or "12.4").replace(".", ""))')" && \
#     uv pip install --system --upgrade --force-reinstall \
#       "flashinfer-cubin==${FLASHINFER_VERSION}" \
#       "flashinfer-jit-cache==${FLASHINFER_VERSION}" \
#       --extra-index-url "https://flashinfer.ai/whl/cu${FLASHINFER_CUDA_TAG}" && \
#     flashinfer show-config
# Uninstall the old nvidia-cublas-cu12 brought by torch/vllm before reinstalling the pinned version
RUN uv pip uninstall --system nvidia-cublas-cu12
# Install vllm-omni into the same uv-managed Python environment used by the base image.
# Use bash -c so that $(python3 -c ...) is expanded inside the container.
RUN /bin/bash -c 'uv pip install --python "$(python3 -c "import sys; print(sys.executable)")" --no-cache-dir -e ".[dev]"'

# Pin nvidia-cublas-cu12 after vllm-omni install so dependency resolution does not overwrite it
RUN uv pip install --system --upgrade --force-reinstall "nvidia-cublas-cu12==12.9.1.4"

RUN ln -sf /usr/bin/python3 /usr/bin/python

ENTRYPOINT []

# vLLM-Omni å¼ºåŒ–å­¦ä¹ (RL)æ”¯æŒåˆ†æ

- **RFC Issue**: [#778](https://github.com/vllm-project/vllm-omni/issues/778)
- **åˆ›å»ºæ—¥æœŸ**: 2026-01-14
- **æœ€åæ›´æ–°**: 2026-02-16

## 1. æ¦‚è¿°

æœ¬æ–‡æ¡£åˆ†æ vLLM-Omni é¡¹ç›®ä¸­ä¸å¼ºåŒ–å­¦ä¹ (RL)ç›¸å…³çš„è®¾è®¡ã€ç°æœ‰è¿›å±•å’Œæœªæ¥è§„åˆ’ã€‚vLLM-Omni æ—¨åœ¨ä¸ [verl](https://github.com/volcengine/verl)ï¼ˆç«å±±å¼•æ“å¼€æºçš„ç”Ÿäº§çº§ RLHF æ¡†æ¶ï¼‰é›†æˆï¼Œæ”¯æŒå¤šæ¨¡æ€æ¨¡å‹çš„ RL è®­ç»ƒæµç¨‹ã€‚

### æ ¸å¿ƒç›®æ ‡

- æ”¯æŒ Ray-based vLLM rollout workers (`VLLMRolloutActor`) ç”¨äºå¹¶è¡Œæ¨ç†
- å®ç° Zero-copy æƒé‡åŒæ­¥ï¼ˆä»è®­ç»ƒ worker åˆ°æ¨ç†å¼•æ“ï¼‰
- å…¼å®¹ DataProto batch protocol åŒå‘æ•°æ®ä¼ è¾“åè®®
- æ”¯æŒå¤šæ¨¡æ€æ¨¡å‹ï¼ˆå¦‚ Qwen2.5-Omni ç­‰ï¼‰çš„ RLHF

## 2. è®¾è®¡æ¶æ„

### 2.1 æ•´ä½“æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       verl RL Framework                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Training Worker   â”‚    â”‚    VLLMRolloutActor (vLLM)    â”‚  â”‚
â”‚  â”‚  (FSDP/Megatron)    â”‚â”€â”€â”€â–¶â”‚      Rollout Generation       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚            â”‚                                   â”‚                â”‚
â”‚            â”‚    Zero-copy Weight Sync          â”‚                â”‚
â”‚            â”‚    DataProto Protocol             â”‚                â”‚
â”‚            â–¼                                   â–¼                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚              vLLM-Omni Rollout Engine                    â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚   â”‚
â”‚  â”‚  â”‚ AsyncOmniLLM â”‚  â”‚AsyncOmniDiff â”‚  â”‚  Custom       â”‚ â”‚   â”‚
â”‚  â”‚  â”‚   (Thinker)  â”‚  â”‚   (Diffusion)â”‚  â”‚  Pipeline     â”‚ â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 å…³é”®ç»„ä»¶

| ç»„ä»¶ | è¯´æ˜ | çŠ¶æ€ |
|------|------|------|
| `AsyncOmniLLM` | å¼‚æ­¥ LLM æ¨ç†å¼•æ“ï¼Œç»§æ‰¿è‡ª vLLM çš„ `AsyncLLM` | âœ… å·²å®Œæˆ |
| `AsyncOmniDiffusion` | å¼‚æ­¥æ‰©æ•£æ¨¡å‹æ¨ç†å¼•æ“ | âœ… å·²å®Œæˆ |
| `DiffusionWorker` | ç®¡ç† GPU åŸºç¡€è®¾æ–½çš„æ‰©æ•£æ¨¡å‹å·¥ä½œå™¨ | âœ… å·²å®Œæˆ |
| `WorkerWrapperBase` | æ”¯æŒæ‰©å±•çš„ Worker åŒ…è£…åŸºç±» | âœ… å·²å®Œæˆ |
| `DiffusionLoRAManager` | LoRA adapter ç®¡ç†å™¨ | âœ… å·²å®Œæˆ |

## 3. ç°æœ‰è¿›å±•

### 3.1 æ¨¡å‹æƒé‡ç®¡ç†ï¼ˆå·²å®Œæˆ âœ“ï¼‰

**ç›¸å…³ Issue/PR**: [#316](https://github.com/vllm-project/vllm-omni/issues/316), [#376](https://github.com/vllm-project/vllm-omni/pull/376)

ä¸ºæ”¯æŒ RL è®­ç»ƒä¸­çš„æƒé‡åŠ¨æ€æ›´æ–°ï¼Œå·²å®ç°ï¼š

- **`sleep(level)`** - å°†æ¨¡å‹æƒé‡å¸è½½åˆ° CPUï¼Œé‡Šæ”¾ GPU å†…å­˜ä¾›è®­ç»ƒä½¿ç”¨
  - Level 1: ä»…å¸è½½æƒé‡
  - Level 2: åŒæ—¶ä¿å­˜ç¼“å†²åŒºçŠ¶æ€
- **`wake_up(tags)`** - ä»ç¡çœ æ¨¡å¼å”¤é†’ï¼Œå°†æƒé‡é‡æ–°åŠ è½½åˆ° GPU
- **`load_weights(weights)`** - åŠ¨æ€åŠ è½½æ–°æƒé‡

**ä»£ç ä½ç½®**: `vllm_omni/diffusion/worker/diffusion_worker.py:204-271`

```python
def sleep(self, level: int = 1) -> bool:
    """Put the worker to sleep, offloading model weights."""
    from vllm.device_allocator.cumem import CuMemAllocator
    allocator = CuMemAllocator.get_instance()
    allocator.sleep(offload_tags=("weights",) if level == 1 else tuple())
    ...

def wake_up(self, tags: list[str] | None = None) -> bool:
    """Wake up the worker from sleep mode."""
    from vllm.device_allocator.cumem import CuMemAllocator
    allocator = CuMemAllocator.get_instance()
    allocator.wake_up(tags)
    ...
```

### 3.2 LoRA é€‚é…å™¨æ”¯æŒï¼ˆå·²å®Œæˆ âœ“ï¼‰

**ç›¸å…³ Issue/PR**: [#281](https://github.com/vllm-project/vllm-omni/issues/281), [#657](https://github.com/vllm-project/vllm-omni/pull/657), [#758](https://github.com/vllm-project/vllm-omni/pull/758)

å®ç°æ‰©æ•£æ¨¡å‹çš„ LoRA æ”¯æŒï¼š

- è¿è¡Œæ—¶åŠ¨æ€åŠ è½½/å¸è½½ LoRA adapterï¼Œæ— éœ€é‡å¯æœåŠ¡
- Per-worker LRU ç¼“å­˜ï¼Œå¯é…ç½® VRAM é¢„ç®—
- PEFT æ ¼å¼å…¼å®¹
- è·¯å¾„ç™½åå•å®‰å…¨æœºåˆ¶
- æ”¯æŒ SD3.5/SDXL ç­‰æ¨¡å‹

**ä»£ç ä½ç½®**: `vllm_omni/diffusion/lora/manager.py`

**å¼‚æ­¥ API ç¤ºä¾‹**:
```python
async def add_lora(self, lora_request: LoRARequest, lora_scale: float = 1.0) -> bool
async def remove_lora(self, adapter_id: int) -> bool
async def list_loras(self) -> list[int]
async def pin_lora(self, lora_id: int) -> bool
```

**vLLM é›†æˆæ­¥éª¤**:
1. åˆå§‹åŒ– LoRA manager
2. Per-request åŠ¨æ€æ¿€æ´» LoRA
3. æ¨ç†æ—¶é€šè¿‡ vLLM è‡ªç ” LoRA å±‚è¿›è¡Œè®¡ç®—

### 3.3 å¼‚æ­¥æ¥å£ / EngineClientï¼ˆå·²å®Œæˆ âœ“ï¼‰

**ç›¸å…³ Issue/PR**: [#342](https://github.com/vllm-project/vllm-omni/issues/342)

å·²æä¾›å…¼å®¹ verl çš„å¼‚æ­¥æ¥å£ï¼š

#### AsyncOmniLLM
- ç»§æ‰¿è‡ª vLLM çš„ `AsyncLLM`
- æ”¯æŒ `from_vllm_config()` ç±»æ–¹æ³•ç”¨äºä»é…ç½®åˆå§‹åŒ–
- æ”¯æŒ `reset_mm_cache()` ç”¨äºé‡ç½®å¤šæ¨¡æ€ç¼“å­˜
- ä¸“ä¸ºå¤šæ¨¡æ€è¾“å…¥/è¾“å‡ºä¼˜åŒ–çš„å¤„ç†å™¨

**ä»£ç ä½ç½®**: `vllm_omni/entrypoints/async_omni_llm.py:32`<br>
**from_vllm_config**: `vllm_omni/entrypoints/async_omni_llm.py:193`

#### AsyncOmniDiffusion
- æ‰©æ•£æ¨¡å‹å¼‚æ­¥æ¨ç†æ¥å£
- ä¸æ”¯æŒ `reset_mm_cache`ï¼ˆæ‰©æ•£æ¨¡å‹å°šæœªæ„å»ºå¤šæ¨¡æ€ç¼“å­˜ç³»ç»Ÿï¼‰
- å®Œæ•´çš„ LoRA API æ”¯æŒ

**ä»£ç ä½ç½®**: `vllm_omni/entrypoints/async_omni_diffusion.py:30`

### 3.4 WorkerWrapperBase ä¸è‡ªå®šä¹‰ Pipelineï¼ˆå·²å®Œæˆ âœ“ï¼‰

**ç›¸å…³ Issue/PR**: [#686](https://github.com/vllm-project/vllm-omni/issues/686), [#764](https://github.com/vllm-project/vllm-omni/pull/764)

å…³é”®å®ç°ï¼š

- **`WorkerWrapperBase`** - ç±»ä¼¼ vLLM è®¾è®¡ï¼Œæ”¯æŒåŠ¨æ€ç»§æ‰¿æ‰©å±•
- **è‡ªå®šä¹‰ Pipeline æ”¯æŒ** - å…è®¸ç”¨æˆ·ä¼ å…¥è‡ªå®šä¹‰ pipeline ç±»
  - æ”¯æŒ RL åœºæ™¯ä¸­çš„ä¸­é—´å˜é‡è¿”å›ï¼ˆprompt embeddingsã€cached latentsï¼‰
  - æ”¯æŒè‡ªå®šä¹‰ schedulerï¼ˆå¦‚ SDE ç‰ˆæœ¬çš„ Euler samplerï¼‰
- **`load_format=dummy`** - æ— æ¨¡å‹åŠ è½½çš„ worker åˆå§‹åŒ–ï¼Œä¾¿äºæµ‹è¯•
- **é€šè¿‡ `re_init_pipeline` æ–¹æ³•åŠ¨æ€æ›´æ¢ pipeline**

**ä»£ç ä½ç½®**: `vllm_omni/diffusion/worker/diffusion_worker.py:488-684`

**æ¶æ„å›¾**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      CustomPipelineWorkerExtension  â”‚ (ç”¨æˆ·æ‰©å±•)
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚         â”‚ DiffusionWorker          â”‚â”‚
â”‚         â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚         â”‚  â”‚ DiffusionModelRunner  â”‚â”‚
â”‚         â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚â”‚
â”‚         â”‚  â”‚  â”‚ Pipeline (Custom) â”‚â”‚â”‚
â”‚         â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## 4. å½“å‰é™åˆ¶

### 4.1 Ray Backend ä¸æ”¯æŒï¼ˆå…³é”®éšœç¢ï¼‰

**çŠ¶æ€**: âŒ æœªæ”¯æŒ<br>
**è¯´æ˜**: Diffusion æ¨¡å‹ç›®å‰ä¸æ”¯æŒ Ray åˆ†å¸ƒå¼æ‰§è¡Œå™¨åç«¯

```python
# verl ä¸­ä½¿ç”¨ Ray å¯åŠ¨ vLLM çš„æ–¹å¼
# vllm_omni ä¸­ diffusion éƒ¨åˆ†å°šä¸å…¼å®¹
from verl.workers.rollout.vllm_rollout import vllm_async_server
```

### 4.2 mm_cache for Diffusion

**çŠ¶æ€**: â“ å¾…è®¨è®º<br>
**è¯´æ˜**: `AsyncOmniDiffusion` å°šæœªæ„å»ºå¤šæ¨¡æ€ç¼“å­˜ç³»ç»Ÿã€‚ä½†å‚ä¸è€… [ZJY0516](https://github.com/ZJY0516) æå‡ºç–‘é—®ï¼šæ‰©æ•£æ¨¡å‹æ˜¯å¦éœ€è¦ `mm_cache`ï¼Ÿ

### 4.3 Batching æ”¯æŒ

**çŠ¶æ€**: âš ï¸ éœ€ä¼˜åŒ–<br>
**è¯´æ˜**:
- æ‰©æ•£æ¨¡å‹æ¨ç†çš„ batching æ”¯æŒåœ¨ç†è®ºä¸Šæ¯”çº¯ diffusers åç«¯æ…¢
- éœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–ä»¥æ”¯æŒ RL è®­ç»ƒä¸­çš„é«˜ååéœ€æ±‚

### 4.4 from_vllm_config å…¼å®¹æ€§

**çŠ¶æ€**: âš ï¸ å¾…å®Œå–„<br>
**è¯´æ˜**: `AsyncOmniDiffusion` éœ€è¦æ”¯æŒç±»ä¼¼ `from_vllm_config` çš„æ¥å£ä»¥å®Œå…¨å…¼å®¹ verl

## 5. Future Work

### 5.1 çŸ­æœŸè§„åˆ’ï¼ˆè¿›è¡Œä¸­ï¼‰

1. **Ray Backend æ”¯æŒ**
   - ä¸º `DiffusionWorker` å®ç° Ray-based åˆ†å¸ƒå¼æ‰§è¡Œå™¨
   - ç›®æ ‡ï¼šå®Œæ•´å…¼å®¹ `verl/workers/rollout/vllm_rollout/vllm_async_server.py`

2. **æ¥å£ç»Ÿä¸€**
   - ä¸º `AsyncOmniDiffusion` æ·»åŠ  `from_vllm_config` ç±»æ–¹æ³•
   - ç¡®ä¿ä¸ `EngineClient` æ¥å£å…¼å®¹

3. **æ€§èƒ½ä¼˜åŒ–**
   - æ‰©æ•£æ¨¡å‹ batching æ¨ç†ä¼˜åŒ–
   - æ”¯æŒåˆ†å¸ƒå¼ executor backend for diffusion

### 5.2 æ¶æ„è®¾è®¡åŸåˆ™

æ ¹æ®ç»´æŠ¤è€… [ZJY0516](https://github.com/ZJY0516) çš„æ„è§ï¼š

> "FYI, I don't want OmniDiffusion be coupled with vllm config"

- **è§£è€¦è®¾è®¡**: `OmniDiffusion` åº”ä¿æŒç‹¬ç«‹æ€§ï¼Œä¸ä¸ vllm é…ç½®è¿‡åº¦è€¦åˆ
- **å¯é€‰åŠŸèƒ½**: `mm_cache` æ˜¯å¦å¼•å…¥æ‰©æ•£æ¨¡å‹éœ€è¿›ä¸€æ­¥è¯„ä¼°
- **æ¨¡å—åŒ–**: ä¿æŒå„ç»„ä»¶çš„ç‹¬ç«‹æ€§å’Œå¯æ›¿æ¢æ€§

### 5.3 verl é›†æˆè·¯çº¿å›¾

```
Phase 1: Core Infrastructure (âœ… Done)
â”œâ”€â”€ Weight management (sleep/wake/load_weights)
â”œâ”€â”€ LoRA adapter support
â”œâ”€â”€ Async interfaces (AsyncOmniLLM, AsyncOmniDiffusion)
â””â”€â”€ WorkerWrapperBase and custom pipeline

Phase 2: Distributed Execution (ğŸ”„ In Progress)
â”œâ”€â”€ Ray backend support for diffusion
â”œâ”€â”€ Distributed executor backend
â””â”€â”€ Batching optimization

Phase 3: Full Integration (ğŸ“… Planned)
â”œâ”€â”€ Complete verl compatibility
â”œâ”€â”€ Performance tuning for RL workloads
â””â”€â”€ Production hardening
```

## 6. ç›¸å…³é“¾æ¥

### Issues
- [#778](https://github.com/vllm-project/vllm-omni/issues/778) - RL Support RFC (æœ¬æ–‡æ¡£åŸºç¡€)
- [#316](https://github.com/vllm-project/vllm-omni/issues/316) - æƒé‡å¸è½½/åŠ è½½åŠŸèƒ½
- [#281](https://github.com/vllm-project/vllm-omni/issues/281) - LoRA é€‚é…å™¨æ”¯æŒ
- [#686](https://github.com/vllm-project/vllm-omni/issues/686) - è‡ªå®šä¹‰ Pipeline æ”¯æŒ

### Pull Requests
- [#376](https://github.com/vllm-project/vllm-omni/pull/376) - sleep/wake å’Œ load_weights æ”¯æŒ (å·²åˆå¹¶)
- [#657](https://github.com/vllm-project/vllm-omni/pull/657) - LoRA è¯·æ±‚è·¯å¾„å’Œ worker ç¼“å­˜ (å·²åˆå¹¶)
- [#758](https://github.com/vllm-project/vllm-omni/pull/758) - LoRA Adapter æ”¯æŒ (å·²åˆå¹¶)
- [#764](https://github.com/vllm-project/vllm-omni/pull/764) - WorkerWrapperBase å’Œ CustomPipeline (å·²åˆå¹¶)

### å¤–éƒ¨å‚è€ƒ
- [verl](https://github.com/volcengine/verl) - ç«å±±å¼•æ“ RLHF æ¡†æ¶
- [mm_grpo](https://github.com/leibniz-csi/mm_grpo) - å¤šæ¨¡æ€ GRPO é¡¹ç›®
- [FlowGRPO](https://github.com/yifan123/flow_grpo)
- [DiffusionNFT](https://github.com/NVlabs/DiffusionNFT)

## 7. å‚ä¸è€…

- **ä¸»è¦è´Ÿè´£äºº**: [@SamitHuang](https://github.com/SamitHuang), [@zhtmike](https://github.com/zhtmike), [@knlnguyen1802](https://github.com/knlnguyen1802)
- **è´¡çŒ®è€…**: [@ZJY0516](https://github.com/ZJY0516), [@hsliuustc0106](https://github.com/hsliuustc0106), [@princepride](https://github.com/princepride), [@KevinZeng08](https://github.com/KevinZeng08)

## 8. æ€»ç»“

vLLM-Omni çš„ RL æ”¯æŒå·²å®Œæˆæ ¸å¿ƒåŸºç¡€è®¾æ–½ï¼š
- âœ… æƒé‡ç®¡ç† (sleep/wake/load_weights)
- âœ… LoRA é€‚é…å™¨æ”¯æŒ
- âœ… å¼‚æ­¥æ¥å£ (AsyncOmniLLM, AsyncOmniDiffusion)
- âœ… è‡ªå®šä¹‰ Pipeline æ”¯æŒ

**å½“å‰ä¸»è¦éšœç¢**: Ray backend å°šä¸æ”¯æŒ diffusion æ¨¡å‹ï¼Œè¿™æ˜¯ä¸ verl å®Œå…¨é›†æˆçš„å…³é”®ã€‚

å®Œæˆ Ray æ”¯æŒåï¼ŒvLLM-Omni å°†æˆä¸ºæ”¯æŒå¤šæ¨¡æ€æ¨¡å‹ RLHF çš„å®Œæ•´æ¨ç†å¼•æ“ã€‚
